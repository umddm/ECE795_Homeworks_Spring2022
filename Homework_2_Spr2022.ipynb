{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_2_Spr2022.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq8U3BtmhtRx"
      },
      "source": [
        "\n",
        "# ECE795 Advanced Big Data Analytics Homework 2 (Due 2/17 before lecture)\n",
        "\n",
        "Set up Pyspark Environment.\n",
        "\n",
        "Tips for Colab:\n",
        "\n",
        "1. You will be disconnected if you are idle for more than 90 minutes and will be mandatorily disconnected after 12 hour connection. \n",
        "\n",
        "2. Once you got disconnected, you need to execute the codes from the beginning to setup the environment again.\n",
        "\n",
        "3. For the purpose of homework, it should be sufficient since each problem should not take more than 5 minutes to generate the results.\n",
        "\n",
        "4. To facilitate the use of Colab, you can use \"MainMenu - Runtime - Run all” to run all the cells in the notebook. So you do not have to click each cell to setup the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XXFEbhsvFWTn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEb4HTRwiaJx"
      },
      "source": [
        "Congrats! Your Colab is ready to run Pyspark.\n",
        "\n",
        "# Read input text file to RDD \n",
        "\n",
        "Download the input data from [here](https://raw.githubusercontent.com/umddm/ECE795_Homeworks_Spring2022/homework_2/Gutenberg.txt)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAISFqHXf7dt"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/umddm/ECE795_Homeworks_Spring2022/homework_2/Gutenberg.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21D9EANUvnwF"
      },
      "source": [
        "Now that we have input data, we can start to do the homework. \n",
        "\n",
        "## Question 1 (4 points): The following RDD, 'sentences', contains all the sentences in the text file. Please use 'flatMap' function to create another RDD called 'words' that contains all the words in the text file, then count the number of distinct words in this RDD.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZeJ7WQCgM8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cd8dda-aa78-49d2-a99f-34471e8f3103"
      },
      "source": [
        "# The following code is from the previous homework\n",
        "from pyspark import SparkConf, SparkContext\n",
        "def removeNonAlpabet(s):\n",
        "    return ''.join([i.lower() for i in s if i.isalpha() or i==' ']).lstrip().rstrip()\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "sentences = sc.textFile('Gutenberg.txt').map(removeNonAlpabet).filter(lambda x: x!='')\n",
        "#Question_1:\n",
        "\n",
        "#Fill out here"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of engelsch woordenboek by k ten bruggencate',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever you may copy it give it away or reuse it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at',\n",
              " 'wwwgutenbergorg if you are not located in the united states you',\n",
              " 'will have to check the laws of the country where you are located before',\n",
              " 'using this ebook',\n",
              " 'title engelsch woordenboek',\n",
              " 'eerste deel engelschnederlandsch']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vYyp5dwOm_"
      },
      "source": [
        "## Question 2 (5 points): For the 'words' RDD in Question 1, please find the its top 10 most frequent words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jECSpcuR-Ds"
      },
      "source": [
        "# Question 2\n",
        "\n",
        "# Fill out here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHVHVQjd4P1"
      },
      "source": [
        "## Question 3 (5 points): The following code will create another RDD called 'stop_words' that contains all the stop words in English. For the 'words' RDD in Question 1, please count its number of words that do not appear in 'stop_words'.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJsxix2Xd3-Q"
      },
      "source": [
        "#Question_3\n",
        "# The following code will create another RDD called 'stop_words' that contains all the 'stop words' in English.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = sc.parallelize(stopwords.words('english'))\n",
        "\n",
        "#Fill out here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIy1IL965Ogm"
      },
      "source": [
        "## Question 4 (16 points, 2 points for each function): Assume an RDD is created from a list of numbers, please determine whether it's appropriate to use each of the the following functions in a 'reduce' operation or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OmbLiCQ5ctu"
      },
      "source": [
        "#Question_4\n",
        "\n",
        "#Function A\n",
        "def functionA(x, y):\n",
        "  if x != y:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#Function B\n",
        "def functionB(x, y):\n",
        "  if x < y :\n",
        "    return x\n",
        "  elif y < x:\n",
        "    return y\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "#Function C\n",
        "def functionC(x, y):\n",
        "  return x - 10 + y\n",
        "\n",
        "#Function D\n",
        "def functionD(x, y):\n",
        "  return x * y + x + y\n",
        "\n",
        "#Function E\n",
        "def functionE(x, y):\n",
        "  return (x + y) ** 2\n",
        "\n",
        "#Function F\n",
        "def functionF(x, y):\n",
        "  return x / 2 + y\n",
        "\n",
        "#Function G\n",
        "def functionG(x, y):\n",
        "  return x ** 2 + y ** 3\n",
        "\n",
        "#Function H\n",
        "def functionH(x, y):\n",
        "  return (x - y) / 2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
